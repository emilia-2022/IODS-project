---
title: 'Assignment 6: Analysis of Longitudinal Data'
output: html_document
date: "2022-12-12"
---
# Week 6 - Analysis of Longitudinal Data

Cannot believe I survived the final week (although I will admit at times it was really a struggle this week). I have never worked with longitudinal data before but - compared with the last two weeks - I found these data sets easier to work with. The outputs from the rat data set seemed intuitive as change in weight was something easy to visualize. However, I struggled with the random intercept model and random slope model. I had no idea how to interpret those outputs!
```{r}
date()
```
## Rat Analysis 
### Step 1: Set-Up

#### Relevant Libraries 
```{r warning = FALSE, message = FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(lattice)   # for box-plots
library(GGally)    # for ggpairs
library(lme4)      # for random intercept model
```

#### Reading in the Data 
```{r, warning=FALSE}
# read data from previously wrangled file (poor formatting because of wd issues)
rats <- read.csv("~/Uni Helsinki/Year One/Teaching Period 2/Open Data Science/IODS-project_2022/data/rats.csv", sep = ",")
```

#### Re-converting categorical variables to factor 
```{r}
rats$ID    <- factor(rats$ID)
rats$group <- factor(rats$group)
```

### Step 2: Numerical Exploration 
#### Numerical 
##### Summaries
```{r}
summary(rats)
```
We can see from the above summary that the weight of the rats ranges from 1 gram to 628 grams and Time from 1 to 64. It is also clear that both ID and group are factor variables, so our previous transformation worked. As longitudinal data (before transformation) does not lend itself well to traditional visual explorations - such as histograms or box plots, all graphical explorations of the data will follow in the coming section. 

### Step 3: Graphical Displays 

#### Individual Weight Profiles 
```{r}
# Draw the plot
ggplot(rats, aes(x = Time, 
                 y = Weight, 
                 linetype = ID, 
                 col = group)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ group, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(200), 
                                max(700))) + # manual setting due to error
  theme_minimal()
```

*Interpretations* 

From the above plots we can see that group 2 and group 3 were heavier than rats in group 1. It also appears that the diet given to those in group 1 did not really influence the rats' weight. In contrast, some rats in both group 2 and group 3 experienced slight weight gain throughout the nine weeks. It appears as though the rats in group 2 experienced the most weight gain on average (around 100 grams over nine weeks) Furthermore, there appears to be an weight outlier in group 2. This rat is of about 200 grams heavier than the other rats in the group. Another outlier in group 2 is a rat who seems to have experienced little weight gain: gaining about 50 grams over the nine weeks. An outlier appears in group 3 as well, where there seems to be a rat who experienced more rapid weight gain than their fellow rats (the dotted line).Let's standardize the data and see if we can spot any changes! 

#### Standardized Individual Weight Profiles 
```{r}
# standardize weight variable  
rats <- rats %>%
  group_by(Time) %>%
  mutate(std_weight = (Weight - mean(Weight))/sd(Weight)) %>%
  ungroup()

# plot with new standardized weight variable
ggplot(rats, aes(x = Time, 
                 y = std_weight, 
                 linetype = ID, 
                 col = group)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ group, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(rats$std_weight), 
                                max(rats$std_weight)))+ 
  theme_minimal()
```

*Interpretations* 

After standarization, we can see that some out the previous "outliers" have changed. For instance, the rat with a higher weight in group 2 actually showed very little weight gain over the nine weeks. Another outlier in group changed and we can see that the rat with the full line actually lost weight over the nine weeks. Perhaps the bigest change though is that rats in group 3 almost all lost weight - with the exception of the dotted line - instead of gained weight like the previous plot indicated. We also can see that rats in group 1 did not actually experience weight gain, most stayed around the same weight they were at week 0. 

### Step 4: Summary Measures  
#### Mean Weight Profiles 
```{r warning = FALSE, message = FALSE}
# Number of rats (per group):
n <- 16

# Summary data with mean and standard error of weight by group and time
rats_summary <- rats %>%
  group_by(group, Time) %>%
  summarise( mean = mean(Weight), se = sd(Weight) ) %>%
  ungroup()

# Plot the mean profiles
ggplot(rats_summary, 
       aes(x = Time, 
           y = mean, 
           linetype = group, shape = group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,3)) +
  geom_errorbar(aes(ymin=mean-se, 
                    ymax=mean+se, 
                    linetype="1"), width=0.3) +
  theme(legend.position = c(0.8,0.2)) +
  scale_y_continuous(name = "mean(Weight) +/- se(Weight)")+ 
  theme_minimal()
```

*Interpretations* 

From the mean weight profile error bar plot we can see that there seems to be high errors present in group 2. This is particularly interesting as this is the group which exhibited the most change in weight according to our previous plots. When compared to group 1, group 3 has higher error rates. As group 1 exhibited the least weight change throughout the weeks so it makes sense that the error is lower. It also had more rats in the group (eight compared to the other groups with only 4) so this could have helped smooth out errors. 

#### Boxplot 
```{r}
rats %>%
  mutate(ID = as.factor(ID)) %>%
  ggplot(aes(x = Time, y = Weight, col = ID)) +
  geom_boxplot() +
  facet_wrap(~group, labeller = label_both) +
  theme_minimal()
```

*Interpretations* 

From the above boxplot we can see that the rats in group 2 and group 3 have larger distributions when compared to group 1. This makes sense as these groups experienced the highest weight changes throughout the weeks: with group 2 gaining weight on average and group 3 losing weight on average. We can also clearly see the outlier who did not experience weight gain in group 2: the rat with ID number 11. 

#### Boxplots of Mean Summary Measures 
```{r warning = FALSE, message = FALSE}
# create a summary data by group and ID with mean as the summary variable (ignoring baseline week 0)
rats_sum_mean <- rats %>%
  filter(Time > 0) %>%
  group_by(group, ID) %>%
  summarise(mean = mean(Weight)) %>%
  ungroup()

# glimpse the data
glimpse(rats_sum_mean)

# Draw a boxplot of the mean versus treatment
ggplot(rats_sum_mean, 
       aes(x = group, 
           y = mean,
           col = group)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), weeks 1-9")+ 
  theme_minimal()

# create new data by filtering outlier 
rat_sum_mean <- rats_sum_mean %>% filter(group == 1 & mean > 238 |
                                         group == 2 & mean < 550 |
                                         group == 3 & mean > 500) 
                                      
# glimpse the new data
glimpse(rat_sum_mean)

# Draw a boxplot of the mean versus treatment
ggplot(rat_sum_mean, 
       aes(x = group, 
           y = mean, 
           col = group)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), weeks 1-9")+ 
  theme_minimal()
```

*Interpretations* 

We Can clearly see how much influenced the outliers had on each group. This is especially true for group 2 which had a highly skewed distribution before removing the outlier. In the second plot - after removing the outliers - we can see that each group is less skewed. However, due to their differing scales it is hard to see more exactly how it influenced each of their distributions. 

### ANOVA 

```{r}
# read data in wide format 

rats_anova <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", header = TRUE, sep = '\t')

# Add the baseline from the original data as a new variable to the summary data
rats_2 <- rats_sum_mean %>%
  mutate(baseline = rats_anova$WD1)

# Fit the linear model with the mean as the response 
fit <- lm(mean ~ baseline + group, data = rats_2)

# Compute the analysis of variance table for the fitted model with anova()
anova(fit)
```
*Interpretations* 

As this data has a sample size of three, we cannot run the two sample T-test. Therefore, ANOVA was ran and the results show us that we have sufficient evidence to reject the null hypothesis that the baseline as p = 3.077e-06 (99% CI). This means that we can say that the mean weight of the rates during the baseline was not equal across all three groups. This confirms what we saw in our box-plot above. 

We can not reject the null hypothesis as firmly for the group variable. As the p-value for group is statistically significant at 90% CI (0.07586) we cannot say with total confidence that the average changes in weight for the rats were not equal between the three rat groups. In simpler terms, we can say only at a 90% level of certainty that the group - and thereby the diet - the rats were on influenced their average change in weight. 

## BPRS Analysis 

### Step 1: Set-up

#### Reading in the Data 
```{r, warning=FALSE}
# read data from previously wrangled file (poor formatting because of wd issues)
bprs <- read.csv("~/Uni Helsinki/Year One/Teaching Period 2/Open Data Science/IODS-project_2022/data/bprs.csv", sep = ",")
```

#### Re-converting categorical variables to factor 
```{r}
bprs$treatment <- factor(bprs$treatment)
bprs$subject   <- factor(bprs$subject)
```

### Step 2: Numerical Exploration 
#### Numerical 
##### Summaries
```{r}
summary(bprs)
```

*Interpretations* 

From the above summary we can see that the bprs test scores range from 18 to 95 with an average scores o 37.66. We can also see that we have two treatment groups with 180 observations and that there are eight weeks. Like the previous analysis, the graphical exploration of the data will follow in the coming section. 

### Step 3: Linear Mixed Effect Model 

#### Initial Visualization 
```{r}
ggplot(bprs, aes(x = week, 
                 y = bprs, 
                 linetype = subject,
                 col = subject)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  scale_y_continuous(name = "bprs") + 
  theme_minimal()
```
*Interpretations* 

From the plot we can see that there is a large variation among subjects and it is hard to see any clear trends. It appears as though there is little difference between the two treatments and that the change in bprs score seems to be dependent on the subject themselves. 

#### Fitting Linear Mixed Models 

##### Inital Regression Model Creation
```{r}
# create a regression model 
bprs_reg <-  lm(bprs ~ week + treatment, data = bprs)

# print out a summary of the model
summary(bprs_reg)
```
*Interpretations* 

From the above model we can see that as the week is significant at the 99% CI (<2e-16). We can also see that there is a negative relationship between week and bprs score with a From coefficient of -2.27. This means that for each increase in week, there should be a 2.27 decrease in the subject's bprs score. However, we can also see that treatment is not statistically significant. This means that there is not a statistically significant relationship between treatment type and the bprs score.

#### Random Intercept Model 
```{r}
# create a random intercept model
bprs_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = bprs, REML = FALSE)

# Print the summary of the model
summary(bprs_ref)
```
*Interpretation* 

From the large estimated variance of the bprs random effects, we can deduce that there is a high degree of variation in the intercepts of regression fits of the individual bprs score profiles. We can also see that the standard errors for intercept and treatment 2 in this model are slightly larger than when compared to the simple regression model above. However, the standard error for week is ever-so slightly lower (0.2081 compared to 0.2524). This could be because the previous model assumed independence and this "will lead to the standard error of a within-subject covariate such as time being larger than it should be because of ignoring the likely within-subject dependences, which will reduce the error variance in the model" (Vehkalahati & Everitt, 2019:178).

#### Random Intercept Model and Random Slope Model 
```{r}
bprs_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = bprs, REML = FALSE)

# print a summary of the model
summary(bprs_ref1)

# perform an ANOVA test on the two models
anova(bprs_ref1, bprs_ref)
```
*Interpretations* 

From the random effects output we can see that 0.9609 is the amount of variability in the slope across weeks. We can also see that when a week's intercept increases by one unit of standard deviation, there is a 0.51 standard deviations decrease in bprs scores. From the ANOVA output we can see that the random slope model is statistically significant at the 95% CI (0.026). This is an improvement on the previous model which was not statistically significant. 

#### Random Intercept Model and Random Slope Model with Interaction 

##### Create Model 
```{r}
# create a random intercept and random slope model with the interaction
bprs_ref_interaction <- lmer(bprs ~ week * treatment + (week | subject), 
                             data = bprs, REML = FALSE)

# print a summary of the model
summary(bprs_ref_interaction)

# perform an ANOVA test on the two models
anova(bprs_ref_interaction, bprs_ref1)
```
*Interpretation* 

It appears as though there were no significant changes from adding an interaction term to our model. From the ANOVA output we can see that the two models are very similar. The previous model, bprs_ref1 was significant at 95% whereas this model is significant at 90%. I thinks this means that we should use the previous model. 

#### Plot observed and fitted values 
```{r figure.width = 10, figure.height = 7}
# draw the plot of bprs with the observed bprs score values
p1 <- ggplot(bprs, aes(x = week, 
                       y = bprs)) +
       geom_line(aes(linetype = subject, 
                     col = treatment)) +
       facet_wrap(~treatment, labeller = label_both) +
       ggtitle("Observed") +
       guides(linetype="none", col = "none") + 
       scale_x_continuous(name = "Week", breaks = seq(0, 60, 20)) +
       scale_y_continuous(name = "BPRS Score") +
       theme(legend.position = "none") +
       theme_minimal()

# Create a vector of the fitted values
Fitted <- fitted(bprs_ref_interaction)

# Create a new column fitted to bprs
bprs$fitted <- Fitted

# draw the plot of bprs with the Fitted values of bprs values
p2 <- ggplot(bprs, aes(x = week, 
                       y = fitted)) +
  geom_line(aes(linetype = subject, col = treatment)) +
  facet_wrap(~treatment, labeller = label_both) +
  ggtitle("Fitted") +
  guides(linetype = guide_legend(nrow = 10)) + 
  scale_x_continuous(name = "Week", breaks = seq(0, 60, 20)) +
  scale_y_continuous(name = "") +
  theme(legend.position = "bottom") +
  theme_minimal()

p1 + p2
```

*Interpretations* 

I am not entirely sure how to interpret these two plots. My initial interpretation is that from the fitted values we can observe how there is little difference between the two treatments effect on bprs scores. We can also see that all subjects experienced a decrease in bprs scores over the course of eight weeks. It would be helpful to plot these lines with less subjects so it would be easier to match the subject from the observed plot to the corresponding line in the fitted plot. 